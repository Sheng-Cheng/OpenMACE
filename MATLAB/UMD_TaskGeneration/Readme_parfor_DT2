This document lists the steps of using the cluster on DT2 to run matlab using a shell script

--------------------------------
* Basic operations:
	1. Logon DT2:
	Open a SSH connection and monitor the job submitted to DT2 by:
	$ ssh DT2USERNAME@login.deepthought2.umd.edu
	Then enter the password
	
	2. Logoff DT2:
	$ bye

--------------------------------
* upload/download file (folder) to/from DT2 lustre (via GLUE):
	1. [Local machine] Connect to the remote server: 
	$ sftp DT2USERNAME@terpconnect.umd.edu
	Use put to send file from local to remote:
	$ put FILE_TO_BE_SENT 
	The above command will place the FILE_TO_BE_SENT under /home on the GLUE server.
	To upload a folder to the remote, first we need to have a target folder that has the same name as the FOLDER_TO_BE_SENT. Upload the FOLDER_TO_BE_SENT using
	$ put -r /FOLDER_TO_BE_SENT
	It will upload the entire foler FOLDER_TO_BE_SENT to the /FOLDER_TO_BE_SENT directory under /home on the GLUE server.

	2. [Local machine] Login deepthought2 by 
	$ ssh DT2USERNAME@login.deepthought2.umd.edu
	Then use mv to move the source files from glue to deepthought2 lustre:
	$ cd /lustre/DT2USERNAME
	$ mv ~/glue_home/FOLDER_TO_BE_SENT ./TARGETFOLDER
	Note that /TARGETFOLDER is under /lustre/DT2USERNAME
	
	3. [SSH DT2] Use nano or vim to edit files, e.g.,
	$ nano trial.sh
	$ vim trial.sh
	
	4. [SSH DT2] Submit job specified by the shell script using
	$ sbatch trial.sh
	The above command will return a JOBID. Use the following command to monitor job status:
	$ watch squeue -u DT2USERNAME
	or 
	$ scontrol show job JOBID
	Once the job is done, there will be two output files: one is generated by DT2 with the prefix "slurm"; the other one is specified by the shell script.

	5. [SSH DT2] Transfer data from /lustre to glue
	$ cp FILE_TO_DOWNLOAD ~/glue_home/
	6. [Local machine]Download file to a local machine using scp 
	$ scp DT2USERNAME@terpconnect.umd.edu:FILE_TO_DOWNLOAD /local_directory

--------------------------------
* data folder for program to run:
	1. After login deepthought2 with SSH, use the following command to go to the data folder:
	$ cd /lustre/DT2USERNAME
	2. Store the files here and also when the program finishes, move the output data or files to the glue system.
	3. use $lustre_usage to display data usage

-------------------------------
* submit/monitor a job
	1. submit a job described by a shell script
	$ sbatch SHELLSCRIPT.sh
	Then a JOBID will be returned
	2. Use the following command to monitor the status of a job:
	$ scontrol show job JOBID
	or
	$ watch squeue -u DT2USERNAME


===============================
Memo: 
	1. MATLAB on the remote server does not accept double quotation marks like in fprintf("..."). Use single quotation marks instead.



==============================
Obsolete:
1. Download the configuration files listed within the section 'MATLAB Parallel Server/Distributed Computing Server' on this webpage: http://hpcc.umd.edu/hpcc/help/software/matlab.html#mdcs

2. Run configCluster each matlab session.

3. Validate the cluster before running scripts in matlab. The validation can be done under the 'HOME' tab, in the 'parallel' dropdown and click 'Select and Manage Clusters...'
